{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/all_speeches_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertopic(texts):\n",
    "    topic_model = BERTopic()\n",
    "    topic_model.fit(texts)\n",
    "    #topics, probs = topic_model.fit_transform(texts)\n",
    "\n",
    "    return topic_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = df['preprocessed_speeches_joined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(speeches[786])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(df.loc[:50,'preprocessed_speeches_joined'])\n",
    "texts_2 = list(df.sample(2000)['preprocessed_speeches_joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 18: expected str instance, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_model \u001b[39m=\u001b[39m BERTopic()\n\u001b[0;32m----> 2\u001b[0m topics, probs \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39;49mfit_transform(texts_2)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/bertopic/_bertopic.py:411\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_representative_docs(custom_documents)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m      \u001b[39m# Extract topics by calculating c-TF-IDF\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_topics(documents, embeddings\u001b[39m=\u001b[39;49membeddings)\n\u001b[1;32m    413\u001b[0m     \u001b[39m# Reduce topics\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnr_topics:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/bertopic/_bertopic.py:3294\u001b[0m, in \u001b[0;36mBERTopic._extract_topics\u001b[0;34m(self, documents, embeddings, mappings)\u001b[0m\n\u001b[1;32m   3285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_extract_topics\u001b[39m(\u001b[39mself\u001b[39m, documents: pd\u001b[39m.\u001b[39mDataFrame, embeddings: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, mappings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3286\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Extract topics from the clusters using a class-based TF-IDF\u001b[39;00m\n\u001b[1;32m   3287\u001b[0m \n\u001b[1;32m   3288\u001b[0m \u001b[39m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3292\u001b[0m \u001b[39m        c_tf_idf: The resulting matrix giving a value (importance score) for each word per topic\u001b[39;00m\n\u001b[1;32m   3293\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3294\u001b[0m     documents_per_topic \u001b[39m=\u001b[39m documents\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mTopic\u001b[39;49m\u001b[39m'\u001b[39;49m], as_index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39;49magg({\u001b[39m'\u001b[39;49m\u001b[39mDocument\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin})\n\u001b[1;32m   3295\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_tf_idf_, words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_tf_idf(documents_per_topic)\n\u001b[1;32m   3296\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopic_representations_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_words_per_topic(words, documents)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/groupby/generic.py:1269\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1266\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m   1268\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m-> 1269\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[1;32m   1270\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1271\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/apply.py:163\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[1;32m    164\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    165\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/apply.py:420\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m         results \u001b[39m=\u001b[39m {key: colg\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    418\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m         \u001b[39m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m--> 420\u001b[0m         results \u001b[39m=\u001b[39m {\n\u001b[1;32m    421\u001b[0m             key: obj\u001b[39m.\u001b[39m_gotitem(key, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    422\u001b[0m         }\n\u001b[1;32m    424\u001b[0m \u001b[39m# set the final keys\u001b[39;00m\n\u001b[1;32m    425\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(arg\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/apply.py:421\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    417\u001b[0m         results \u001b[39m=\u001b[39m {key: colg\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    418\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m         \u001b[39m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m    420\u001b[0m         results \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 421\u001b[0m             key: obj\u001b[39m.\u001b[39;49m_gotitem(key, ndim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    422\u001b[0m         }\n\u001b[1;32m    424\u001b[0m \u001b[39m# set the final keys\u001b[39;00m\n\u001b[1;32m    425\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(arg\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/groupby/generic.py:269\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_agg_general(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_agg_general(func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[39m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[39m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[39m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_named(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/groupby/generic.py:288\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    287\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_with_exclusions\n\u001b[0;32m--> 288\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(obj, f)\n\u001b[1;32m    289\u001b[0m res \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_constructor(result, name\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mname)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/groupby/ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39m_values, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    988\u001b[0m     \u001b[39m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[39m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[39m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[39m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    996\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    997\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/groupby/ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1012\u001b[0m splitter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_splitter(obj, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   1014\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[0;32m-> 1015\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[1;32m   1016\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n\u001b[1;32m   1018\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[1;32m   1019\u001b[0m         \u001b[39m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/pandas/core/groupby/generic.py:285\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_agg_general\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    284\u001b[0m     func \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mis_builtin_func(func)\n\u001b[0;32m--> 285\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: func(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    287\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39magg_series(obj, f)\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 18: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(texts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>83</td>\n",
       "      <td>-1_united_international_nations_world</td>\n",
       "      <td>[united, international, nations, world, people...</td>\n",
       "      <td>[mr president pleasure first offer behalf beha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0_united_international_world_people</td>\n",
       "      <td>[united, international, world, people, nations...</td>\n",
       "      <td>[﻿it great satisfaction welcome election mr ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1_international_united_nations_world</td>\n",
       "      <td>[international, united, nations, world, develo...</td>\n",
       "      <td>[like behalf delegation behalf congratulate pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                   Name  \\\n",
       "0     -1     83  -1_united_international_nations_world   \n",
       "1      0     94    0_united_international_world_people   \n",
       "2      1     23   1_international_united_nations_world   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [united, international, nations, world, people...   \n",
       "1  [united, international, world, people, nations...   \n",
       "2  [international, united, nations, world, develo...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [mr president pleasure first offer behalf beha...  \n",
       "1  [﻿it great satisfaction welcome election mr ca...  \n",
       "2  [like behalf delegation behalf congratulate pr...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n",
      "(-1, 0.0)\n"
     ]
    }
   ],
   "source": [
    "for z in zip(topics, probs):\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info().to_csv('../raw_data/bertopics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speeches-UN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
