{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_model = KeyBERTInspired()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/all_speeches_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bertopic(texts):\n",
    "    topic_model = BERTopic()\n",
    "    topic_model.fit(texts)\n",
    "    #topics, probs = topic_model.fit_transform(texts)\n",
    "\n",
    "    return topic_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(df['preprocessed_speeches_joined'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_model \u001b[39m=\u001b[39m BERTopic()\n\u001b[0;32m----> 2\u001b[0m topics, probs \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39;49mfit_transform(texts)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/bertopic/_bertopic.py:373\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39mif\u001b[39;00m embeddings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model \u001b[39m=\u001b[39m select_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model,\n\u001b[1;32m    372\u001b[0m                                           language\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguage)\n\u001b[0;32m--> 373\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_embeddings(documents\u001b[39m.\u001b[39;49mDocument\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mtolist(),\n\u001b[1;32m    374\u001b[0m                                           images\u001b[39m=\u001b[39;49mimages,\n\u001b[1;32m    375\u001b[0m                                           method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdocument\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    376\u001b[0m                                           verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose)\n\u001b[1;32m    377\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mTransformed documents to Embeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    378\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/bertopic/_bertopic.py:3126\u001b[0m, in \u001b[0;36mBERTopic._extract_embeddings\u001b[0;34m(self, documents, images, method, verbose)\u001b[0m\n\u001b[1;32m   3124\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_model\u001b[39m.\u001b[39membed_words(words\u001b[39m=\u001b[39mdocuments, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m   3125\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 3126\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49membed_documents(documents, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m   3127\u001b[0m \u001b[39melif\u001b[39;00m documents[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m images \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMake sure to use an embedding model that can either embed documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3129\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mor images depending on which you want to embed.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/bertopic/backend/_base.py:69\u001b[0m, in \u001b[0;36mBaseEmbedder.embed_documents\u001b[0;34m(self, document, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_documents\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m                     document: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m     57\u001b[0m                     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Embed a list of n words into an n-dimensional\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed(document, verbose)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/bertopic/backend/_sentencetransformers.py:65\u001b[0m, in \u001b[0;36mSentenceTransformerBackend.embed\u001b[0;34m(self, documents, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     52\u001b[0m           documents: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m     53\u001b[0m           verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     54\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Embed a list of n documents/words into an n-dimensional\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    matrix of embeddings\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m        that each have an embeddings size of `m`\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_model\u001b[39m.\u001b[39;49mencode(documents, show_progress_bar\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1016\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1017\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[1;32m   1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1021\u001b[0m     embedding_output,\n\u001b[1;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:235\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    233\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 235\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposition_embeddings(position_ids)\n\u001b[1;32m    236\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[1;32m    237\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/speeches-UN/lib/python3.10/site-packages/torch/nn/modules/module.py:1601\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_backward_pre_hooks\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1599\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39m=\u001b[39m OrderedDict()\n\u001b[0;32m-> 1601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m   1602\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1603\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never man throughout world fervently unanimous...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_united_international_nations_world</td>\n",
       "      <td>[united, international, nations, world, people...</td>\n",
       "      <td>[speak member delegation    wish address presi...</td>\n",
       "      <td>united - international - nations - world - peo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>five year since united nations charter lay fun...</td>\n",
       "      <td>2</td>\n",
       "      <td>2_united_nations_nation_world</td>\n",
       "      <td>[united, nations, nation, world, must, charter...</td>\n",
       "      <td>[﻿   period united nations see many marginal g...</td>\n",
       "      <td>united - nations - nation - world - must - cha...</td>\n",
       "      <td>0.872692</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conclusion general discussion much eloquence e...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_united_international_nations_world</td>\n",
       "      <td>[united, international, nations, world, people...</td>\n",
       "      <td>[speak member delegation    wish address presi...</td>\n",
       "      <td>united - international - nations - world - peo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic  \\\n",
       "0  never man throughout world fervently unanimous...     -1   \n",
       "1  five year since united nations charter lay fun...      2   \n",
       "2  conclusion general discussion much eloquence e...     -1   \n",
       "\n",
       "                                    Name  \\\n",
       "0  -1_united_international_nations_world   \n",
       "1          2_united_nations_nation_world   \n",
       "2  -1_united_international_nations_world   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [united, international, nations, world, people...   \n",
       "1  [united, nations, nation, world, must, charter...   \n",
       "2  [united, international, nations, world, people...   \n",
       "\n",
       "                                 Representative_Docs  \\\n",
       "0  [speak member delegation    wish address presi...   \n",
       "1  [﻿   period united nations see many marginal g...   \n",
       "2  [speak member delegation    wish address presi...   \n",
       "\n",
       "                                         Top_n_words  Probability  \\\n",
       "0  united - international - nations - world - peo...     0.000000   \n",
       "1  united - nations - nation - world - must - cha...     0.872692   \n",
       "2  united - international - nations - world - peo...     0.000000   \n",
       "\n",
       "   Representative_document  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speechs_bertopic = topic_model.get_document_info(texts)\n",
    "speechs_bertopic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never man throughout world fervently unanimous...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_united_international_nations_world</td>\n",
       "      <td>[united, international, nations, world, people...</td>\n",
       "      <td>[speak member delegation    wish address presi...</td>\n",
       "      <td>united - international - nations - world - peo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>five year since united nations charter lay fun...</td>\n",
       "      <td>2</td>\n",
       "      <td>2_united_nations_nation_world</td>\n",
       "      <td>[united, nations, nation, world, must, charter...</td>\n",
       "      <td>[﻿   period united nations see many marginal g...</td>\n",
       "      <td>united - nations - nation - world - must - cha...</td>\n",
       "      <td>0.872692</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conclusion general discussion much eloquence e...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_united_international_nations_world</td>\n",
       "      <td>[united, international, nations, world, people...</td>\n",
       "      <td>[speak member delegation    wish address presi...</td>\n",
       "      <td>united - international - nations - world - peo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>may permit congratulate general assembly choic...</td>\n",
       "      <td>17</td>\n",
       "      <td>17_world_great_nation_may</td>\n",
       "      <td>[world, great, nation, may, one, power, proble...</td>\n",
       "      <td>[﻿ \\t mr president first word   express behalf...</td>\n",
       "      <td>world - great - nation - may - one - power - p...</td>\n",
       "      <td>0.788110</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>era inaugurate creation united nations one cri...</td>\n",
       "      <td>12</td>\n",
       "      <td>12_economic_development_country_develop</td>\n",
       "      <td>[economic, development, country, develop, inte...</td>\n",
       "      <td>[﻿my   delegation warmly congratulate sir elec...</td>\n",
       "      <td>economic - development - country - develop - i...</td>\n",
       "      <td>0.947012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td>enormously difficult year united nations   ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2_united_nations_nation_world</td>\n",
       "      <td>[united, nations, nation, world, must, charter...</td>\n",
       "      <td>[﻿   period united nations see many marginal g...</td>\n",
       "      <td>united - nations - nation - world - must - cha...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10394</th>\n",
       "      <td>outset    would like congratulate good friend ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5_development_sustainable_goal_global</td>\n",
       "      <td>[development, sustainable, goal, global, mdgs,...</td>\n",
       "      <td>[   government warmly welcome theme propose   ...</td>\n",
       "      <td>development - sustainable - goal - global - md...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>sixtyninth session general assembly take    pl...</td>\n",
       "      <td>116</td>\n",
       "      <td>116_ebola_epidemic_terrorist_development</td>\n",
       "      <td>[ebola, epidemic, terrorist, development, woma...</td>\n",
       "      <td>[great pleasure address    general assembly si...</td>\n",
       "      <td>ebola - epidemic - terrorist - development - w...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>next year    celebrate seventieth anniversary ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_united_international_nations_world</td>\n",
       "      <td>[united, international, nations, world, people...</td>\n",
       "      <td>[speak member delegation    wish address presi...</td>\n",
       "      <td>united - international - nations - world - peo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>\" seek peace prepare war \" word publius flaviu...</td>\n",
       "      <td>19</td>\n",
       "      <td>19_climate_change_global_must</td>\n",
       "      <td>[climate, change, global, must, challenge, nee...</td>\n",
       "      <td>[would like begin personal note thank previous...</td>\n",
       "      <td>climate - change - global - must - challenge -...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10398 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Document  Topic  \\\n",
       "0      never man throughout world fervently unanimous...     -1   \n",
       "1      five year since united nations charter lay fun...      2   \n",
       "2      conclusion general discussion much eloquence e...     -1   \n",
       "3      may permit congratulate general assembly choic...     17   \n",
       "4      era inaugurate creation united nations one cri...     12   \n",
       "...                                                  ...    ...   \n",
       "10393     enormously difficult year united nations   ...      2   \n",
       "10394  outset    would like congratulate good friend ...      5   \n",
       "10395  sixtyninth session general assembly take    pl...    116   \n",
       "10396  next year    celebrate seventieth anniversary ...     -1   \n",
       "10397  \" seek peace prepare war \" word publius flaviu...     19   \n",
       "\n",
       "                                           Name  \\\n",
       "0         -1_united_international_nations_world   \n",
       "1                 2_united_nations_nation_world   \n",
       "2         -1_united_international_nations_world   \n",
       "3                     17_world_great_nation_may   \n",
       "4       12_economic_development_country_develop   \n",
       "...                                         ...   \n",
       "10393             2_united_nations_nation_world   \n",
       "10394     5_development_sustainable_goal_global   \n",
       "10395  116_ebola_epidemic_terrorist_development   \n",
       "10396     -1_united_international_nations_world   \n",
       "10397             19_climate_change_global_must   \n",
       "\n",
       "                                          Representation  \\\n",
       "0      [united, international, nations, world, people...   \n",
       "1      [united, nations, nation, world, must, charter...   \n",
       "2      [united, international, nations, world, people...   \n",
       "3      [world, great, nation, may, one, power, proble...   \n",
       "4      [economic, development, country, develop, inte...   \n",
       "...                                                  ...   \n",
       "10393  [united, nations, nation, world, must, charter...   \n",
       "10394  [development, sustainable, goal, global, mdgs,...   \n",
       "10395  [ebola, epidemic, terrorist, development, woma...   \n",
       "10396  [united, international, nations, world, people...   \n",
       "10397  [climate, change, global, must, challenge, nee...   \n",
       "\n",
       "                                     Representative_Docs  \\\n",
       "0      [speak member delegation    wish address presi...   \n",
       "1      [﻿   period united nations see many marginal g...   \n",
       "2      [speak member delegation    wish address presi...   \n",
       "3      [﻿ \\t mr president first word   express behalf...   \n",
       "4      [﻿my   delegation warmly congratulate sir elec...   \n",
       "...                                                  ...   \n",
       "10393  [﻿   period united nations see many marginal g...   \n",
       "10394  [   government warmly welcome theme propose   ...   \n",
       "10395  [great pleasure address    general assembly si...   \n",
       "10396  [speak member delegation    wish address presi...   \n",
       "10397  [would like begin personal note thank previous...   \n",
       "\n",
       "                                             Top_n_words  Probability  \\\n",
       "0      united - international - nations - world - peo...     0.000000   \n",
       "1      united - nations - nation - world - must - cha...     0.872692   \n",
       "2      united - international - nations - world - peo...     0.000000   \n",
       "3      world - great - nation - may - one - power - p...     0.788110   \n",
       "4      economic - development - country - develop - i...     0.947012   \n",
       "...                                                  ...          ...   \n",
       "10393  united - nations - nation - world - must - cha...     1.000000   \n",
       "10394  development - sustainable - goal - global - md...     1.000000   \n",
       "10395  ebola - epidemic - terrorist - development - w...     1.000000   \n",
       "10396  united - international - nations - world - peo...     0.000000   \n",
       "10397  climate - change - global - must - challenge -...     1.000000   \n",
       "\n",
       "       Representative_document  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "...                        ...  \n",
       "10393                    False  \n",
       "10394                    False  \n",
       "10395                    False  \n",
       "10396                    False  \n",
       "10397                    False  \n",
       "\n",
       "[10398 rows x 8 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speechs_bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f0d8d71b9a0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_group = speechs_bertopic.groupby(speechs_bertopic['Topic'])\n",
    "topics_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dictionary(df):\n",
    "    topics_dictionary = {speechs_bertopic['Topic']: speechs_bertopic['Name'] for _, speechs_bertopic in df.iterrows()}\n",
    "    return topics_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = dataframe_to_dictionary(speechs_bertopic)\n",
    "topics=list(topics_dict.values())\n",
    "topics_df = pd.DataFrame([each.split('_') for each in topics])\n",
    "\n",
    "topics_df_no_index = topics_df.iloc[:,1:]\n",
    "topics_df_no_index['sentence'] = topics_df_no_index[1] + ' ' + topics_df_no_index[2] + ' ' + topics_df_no_index[3] + ' ' + topics_df_no_index[4]\n",
    "\n",
    "topics_df_no_index\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Calculate similarities between sentences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02532696,  0.04260313,  0.02453121, ..., -0.03447136,\n",
       "         0.03656168,  0.0299756 ],\n",
       "       [ 0.03246542,  0.07522053,  0.01142967, ..., -0.0235924 ,\n",
       "         0.0291353 ,  0.01690031],\n",
       "       [-0.01489892,  0.08762721, -0.0061089 , ...,  0.01071687,\n",
       "         0.00246285, -0.0110433 ],\n",
       "       ...,\n",
       "       [-0.01507586,  0.04847073, -0.00300311, ...,  0.01349797,\n",
       "         0.01224935,  0.00860086],\n",
       "       [ 0.0169589 ,  0.08714733,  0.01753104, ..., -0.02185655,\n",
       "         0.04019306,  0.01092129],\n",
       "       [ 0.01892271,  0.06278684,  0.00873006, ...,  0.03447561,\n",
       "        -0.02178571, -0.02646308]], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split text into sentences\n",
    "# Embed sentences\n",
    "embeddings = model.encode(topics_df_no_index['sentence'])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>0.024531</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>-0.010761</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>0.083466</td>\n",
       "      <td>-0.016115</td>\n",
       "      <td>0.049136</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038960</td>\n",
       "      <td>0.042155</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.012728</td>\n",
       "      <td>-0.016302</td>\n",
       "      <td>-0.100730</td>\n",
       "      <td>-0.003941</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.036562</td>\n",
       "      <td>0.029976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032465</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>0.011430</td>\n",
       "      <td>0.017460</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>-0.017086</td>\n",
       "      <td>0.026574</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036187</td>\n",
       "      <td>0.032743</td>\n",
       "      <td>-0.010834</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>-0.025772</td>\n",
       "      <td>-0.090289</td>\n",
       "      <td>-0.013991</td>\n",
       "      <td>-0.023592</td>\n",
       "      <td>0.029135</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.014899</td>\n",
       "      <td>0.087627</td>\n",
       "      <td>-0.006109</td>\n",
       "      <td>-0.026698</td>\n",
       "      <td>0.047849</td>\n",
       "      <td>0.021846</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>0.020747</td>\n",
       "      <td>0.019004</td>\n",
       "      <td>0.038799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020846</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.056431</td>\n",
       "      <td>-0.022545</td>\n",
       "      <td>-0.009104</td>\n",
       "      <td>-0.039657</td>\n",
       "      <td>-0.034324</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>-0.011043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.012207</td>\n",
       "      <td>0.067414</td>\n",
       "      <td>-0.032880</td>\n",
       "      <td>-0.003286</td>\n",
       "      <td>0.044688</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>-0.016533</td>\n",
       "      <td>0.040690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019370</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>-0.001341</td>\n",
       "      <td>-0.017762</td>\n",
       "      <td>-0.033847</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>0.030445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022234</td>\n",
       "      <td>-0.030979</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>-0.012184</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>-0.040202</td>\n",
       "      <td>0.036405</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.051425</td>\n",
       "      <td>0.036577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050498</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>-0.018918</td>\n",
       "      <td>-0.010653</td>\n",
       "      <td>0.016513</td>\n",
       "      <td>-0.076608</td>\n",
       "      <td>0.029525</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.053178</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.023531</td>\n",
       "      <td>-0.036965</td>\n",
       "      <td>-0.052610</td>\n",
       "      <td>-0.006481</td>\n",
       "      <td>0.050592</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>0.032958</td>\n",
       "      <td>0.051601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054016</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.037646</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>-0.025155</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>0.045133</td>\n",
       "      <td>-0.003551</td>\n",
       "      <td>0.018306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.018155</td>\n",
       "      <td>0.052087</td>\n",
       "      <td>0.014597</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>-0.057397</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>-0.012189</td>\n",
       "      <td>-0.034532</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048675</td>\n",
       "      <td>0.038447</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>-0.037381</td>\n",
       "      <td>-0.006895</td>\n",
       "      <td>0.027705</td>\n",
       "      <td>-0.039655</td>\n",
       "      <td>0.035043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-0.015076</td>\n",
       "      <td>0.048471</td>\n",
       "      <td>-0.003003</td>\n",
       "      <td>-0.008084</td>\n",
       "      <td>-0.058567</td>\n",
       "      <td>-0.044945</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>-0.044957</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024588</td>\n",
       "      <td>-0.009126</td>\n",
       "      <td>0.043233</td>\n",
       "      <td>0.025231</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>-0.077895</td>\n",
       "      <td>-0.007729</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.008601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.016959</td>\n",
       "      <td>0.087147</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>-0.004955</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.040053</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>0.021556</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023709</td>\n",
       "      <td>-0.030061</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>-0.027109</td>\n",
       "      <td>-0.099165</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>-0.021857</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>0.010921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.018923</td>\n",
       "      <td>0.062787</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>-0.014272</td>\n",
       "      <td>-0.045411</td>\n",
       "      <td>-0.065884</td>\n",
       "      <td>0.042578</td>\n",
       "      <td>-0.023315</td>\n",
       "      <td>-0.024723</td>\n",
       "      <td>0.011318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039768</td>\n",
       "      <td>0.013096</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>-0.022666</td>\n",
       "      <td>0.016421</td>\n",
       "      <td>0.014435</td>\n",
       "      <td>-0.013785</td>\n",
       "      <td>0.034476</td>\n",
       "      <td>-0.021786</td>\n",
       "      <td>-0.026463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.025327  0.042603  0.024531  0.004825 -0.010761 -0.001017  0.083466   \n",
       "1    0.032465  0.075221  0.011430  0.017460  0.007925  0.005901  0.067572   \n",
       "2   -0.014899  0.087627 -0.006109 -0.026698  0.047849  0.021846 -0.001409   \n",
       "3   -0.012207  0.067414 -0.032880 -0.003286  0.044688  0.017098  0.018087   \n",
       "4    0.022234 -0.030979 -0.003015 -0.012184  0.005421 -0.040202  0.036405   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "130  0.053178  0.021886  0.023531 -0.036965 -0.052610 -0.006481  0.050592   \n",
       "131  0.018155  0.052087  0.014597  0.003110 -0.057397  0.002639  0.010976   \n",
       "132 -0.015076  0.048471 -0.003003 -0.008084 -0.058567 -0.044945  0.020873   \n",
       "133  0.016959  0.087147  0.017531  0.009149 -0.004955  0.005664  0.040053   \n",
       "134  0.018923  0.062787  0.008730 -0.014272 -0.045411 -0.065884  0.042578   \n",
       "\n",
       "          7         8         9    ...       758       759       760  \\\n",
       "0   -0.016115  0.049136  0.007077  ... -0.038960  0.042155  0.004093   \n",
       "1   -0.017086  0.026574  0.007963  ... -0.036187  0.032743 -0.010834   \n",
       "2    0.020747  0.019004  0.038799  ...  0.020846  0.010451  0.056431   \n",
       "3    0.011204 -0.016533  0.040690  ... -0.019370 -0.001263 -0.002546   \n",
       "4    0.002711  0.051425  0.036577  ... -0.050498  0.003400 -0.018918   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "130 -0.015032  0.032958  0.051601  ... -0.054016  0.005894  0.037646   \n",
       "131 -0.012189 -0.034532  0.003408  ... -0.048675  0.038447  0.002316   \n",
       "132  0.008290 -0.044957  0.024952  ... -0.024588 -0.009126  0.043233   \n",
       "133  0.006793  0.021556  0.004394  ... -0.023709 -0.030061  0.013795   \n",
       "134 -0.023315 -0.024723  0.011318  ... -0.039768  0.013096 -0.000387   \n",
       "\n",
       "          761       762       763       764       765       766       767  \n",
       "0    0.012728 -0.016302 -0.100730 -0.003941 -0.034471  0.036562  0.029976  \n",
       "1   -0.002314 -0.025772 -0.090289 -0.013991 -0.023592  0.029135  0.016900  \n",
       "2   -0.022545 -0.009104 -0.039657 -0.034324  0.010717  0.002463 -0.011043  \n",
       "3    0.024688  0.020760 -0.001341 -0.017762 -0.033847 -0.010894  0.030445  \n",
       "4   -0.010653  0.016513 -0.076608  0.029525  0.018341 -0.011866 -0.000398  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "130  0.010478  0.007639 -0.025155 -0.000765  0.045133 -0.003551  0.018306  \n",
       "131 -0.000590  0.015042 -0.037381 -0.006895  0.027705 -0.039655  0.035043  \n",
       "132  0.025231  0.029598 -0.077895 -0.007729  0.013498  0.012249  0.008601  \n",
       "133  0.021918 -0.027109 -0.099165 -0.007376 -0.021857  0.040193  0.010921  \n",
       "134 -0.022666  0.016421  0.014435 -0.013785  0.034476 -0.021786 -0.026463  \n",
       "\n",
       "[135 rows x 768 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df = pd.DataFrame(embeddings)\n",
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_df = pca.fit_transform(embedding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=24)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=24)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=24)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmean = KMeans(n_clusters=24)\n",
    "kmean.fit(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df['label'] = kmean.labels_\n",
    "topics_df['label'] = kmean.labels_\n",
    "topics_df.to_csv('~/code/renzorico/speeches-at-UN/raw_data/topics')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inertias = []\n",
    "# ks = range(1,100)\n",
    "\n",
    "# for k in ks:\n",
    "#     km_test = KMeans(n_clusters=k).fit(pca_df)\n",
    "#     inertias.append(km_test.inertia_)\n",
    "\n",
    "# plt.plot(ks, inertias)\n",
    "# plt.xlabel('k cluster number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_document_info(texts).to_csv('../raw_data/bertopics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -1\n",
       "1          2\n",
       "2         -1\n",
       "3         17\n",
       "4         12\n",
       "        ... \n",
       "10393      2\n",
       "10394      5\n",
       "10395    116\n",
       "10396     -1\n",
       "10397     19\n",
       "Name: Topic, Length: 10398, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speechs_bertopic['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>127</td>\n",
       "      <td>principle</td>\n",
       "      <td>problem</td>\n",
       "      <td>shall</td>\n",
       "      <td>state</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>66</td>\n",
       "      <td>somali</td>\n",
       "      <td>government</td>\n",
       "      <td>transitional</td>\n",
       "      <td>africa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>46</td>\n",
       "      <td>food</td>\n",
       "      <td>crisis</td>\n",
       "      <td>global</td>\n",
       "      <td>price</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>89</td>\n",
       "      <td>fortyeighth</td>\n",
       "      <td>development</td>\n",
       "      <td>session</td>\n",
       "      <td>security</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0            1            2             3         4  label\n",
       "96   127    principle      problem         shall     state      1\n",
       "99    66       somali   government  transitional    africa      1\n",
       "103   46         food       crisis        global     price      1\n",
       "129   89  fortyeighth  development       session  security      1"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.loc[topics_df.label == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speeches-UN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
